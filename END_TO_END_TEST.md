# ğŸ¤ Voice Interview - End-to-End Testing

## âœ… System Status

All services are **RUNNING**:
- âœ… Voice Service (FastAPI): http://localhost:8000
- âœ… Backend (WebSocket): http://localhost:5000 (WS: ws://localhost:5000/ws/voice)
- âœ… Client (React): http://localhost:3000

## ğŸ§ª Test Steps

### 1. Open the Application
Navigate to: **http://localhost:3000**

You should see the Voice Interview interface with:
- Green "â— Connected" badge (top right)
- "Conceptual Interview" title
- "Start Interview" button

### 2. Start the Interview
**Action**: Click the **"Start Interview"** button

**Expected Behavior**:
- âœ… Button disappears
- âœ… Progress bar appears showing "Question 1 of 5"
- âœ… First question displays in text
- âœ… AI speaks the question (audio should play automatically)
- âœ… "ğŸ”Š AI is speaking..." indicator shows

**What's Happening Behind the Scenes**:
```
Frontend â†’ WebSocket â†’ Backend (start_interview)
Backend â†’ Generate question
Backend â†’ Voice Service (/voice/tts)
Voice Service â†’ ElevenLabs API
Audio streams back â†’ Frontend plays
```

### 3. Record Your Answer
**Action**: 
1. Wait for AI to finish speaking
2. Click **"Start Recording"** button
3. **Allow microphone access** when browser prompts
4. Speak your answer (e.g., "A process is an independent execution unit...")
5. Click **"Stop Recording"**

**Expected Behavior**:
- âœ… Recording indicator (red pulsing dot) appears
- âœ… "Recording..." text shows
- âœ… After stopping, "Your Answer" section updates with transcribed text
- âœ… Green evaluation panel appears showing score and feedback
- âœ… After ~2 seconds, next question loads automatically

**What's Happening**:
```
Microphone â†’ MediaRecorder â†’ Audio chunks (base64)
Frontend â†’ WebSocket (audio_chunk messages)
Backend â†’ Buffers chunks
Backend â†’ Voice Service (/voice/stt)
Voice Service â†’ Groq Whisper API
Transcription â†’ Backend â†’ Frontend (displays)
Backend â†’ Evaluates answer (currently mock)
Backend â†’ Generates next question
Cycle repeats...
```

### 4. Skip a Question (Optional)
**Action**: Click **"Skip Question"** button

**Expected Behavior**:
- âœ… Current answer shows "[Skipped]"
- âœ… Next question loads immediately
- âœ… Progress bar updates

### 5. Complete the Interview
**Action**: Complete all 5 questions

**Expected Behavior**:
- âœ… After question 5, interview ends
- âœ… Alert popup shows:
  - Total score
  - Max score
  - Questions answered
- âœ… Console shows completion data

## ğŸ” Debugging Checklist

### If WebSocket Won't Connect
**Check Backend Terminal**:
```bash
# Should see:
WebSocket server initialized at /ws/voice
[WebSocket] New connection: [uuid]
```

**Check Browser Console** (F12 â†’ Console):
```
WebSocket connected
Received: connected
```

### If No Audio Plays
**Check Voice Service Terminal**:
```bash
# Should see HTTP requests:
INFO: 127.0.0.1:xxxxx - "POST /voice/tts HTTP/1.1" 200 OK
```

**Browser Console**:
```
Received: audio_stream_start
Received: audio_chunk (multiple times)
Received: audio_stream_end
```

**Common Issues**:
- âŒ ElevenLabs API key invalid â†’ Check GithubFeature/.env
- âŒ Browser audio blocked â†’ Click speaker icon in address bar
- âŒ No speakers/volume muted â†’ Check system audio

### If Recording Doesn't Work
**Browser Console**:
```
Error starting recording: ...
```

**Common Issues**:
- âŒ Microphone permission denied â†’ Allow in browser settings
- âŒ No microphone detected â†’ Check system settings
- âŒ HTTPS required (some browsers) â†’ Use http://localhost (should work)

### If Transcription Fails
**Backend Terminal**:
```bash
[STT Error] [sessionId]: ...
```

**Check**:
- âŒ Groq API key invalid â†’ Check GithubFeature/.env
- âŒ Audio format unsupported â†’ Check browser's MediaRecorder format

## ğŸ“Š Monitor in Real-Time

### Terminal 1: Voice Service (FastAPI)
Watch for:
```
INFO: 127.0.0.1:xxxxx - "POST /voice/tts HTTP/1.1" 200 OK
INFO: 127.0.0.1:xxxxx - "POST /voice/stt HTTP/1.1" 200 OK
```

### Terminal 2: Backend (Node.js)
Watch for:
```
[WebSocket] New connection: [uuid]
[WebSocket] [uuid] received: start_interview
[Interview] [uuid] started: conceptual
[Audio] [uuid] processing X chunks
[STT] [uuid] transcription: ...
[TTS] [uuid] audio streaming complete
```

### Terminal 3: Browser Console (F12)
Watch for:
```
WebSocket connected
Received: connected
Received: ai_question
Received: audio_stream_start
Received: audio_chunk (many)
Received: audio_stream_end
Received: transcription
Received: evaluation
```

## âœ… Success Criteria

### Minimum Viable Test
- [ ] WebSocket connects (green badge)
- [ ] Interview starts
- [ ] AI speaks question (audio plays)
- [ ] Can record audio (microphone works)
- [ ] Transcription appears
- [ ] Next question loads

### Full Flow Test
- [ ] Complete all 5 questions
- [ ] Audio playback is smooth
- [ ] Transcriptions are accurate
- [ ] Progress bar updates correctly
- [ ] Final score appears
- [ ] No errors in any terminal

## ğŸ› Known Issues

1. **First audio chunk delay**: 2-3 seconds latency for TTS (ElevenLabs API)
2. **Pydantic warning**: Harmless Python 3.14 compatibility warning
3. **Questions are placeholders**: Real AI integration (Gemini) not yet implemented
4. **Scores are random**: Evaluation logic needs Gemini integration

## ğŸ¯ Next Steps After Testing

If basic flow works:
1. âœ… Mark "Test basic audio flow" as complete
2. ğŸ”„ Integrate Gemini AI for:
   - Real question generation
   - Answer evaluation
3. ğŸ”„ Add conversation context
4. ğŸ”„ Implement project interview mode
5. ğŸ”„ Add database persistence

## ğŸ“ Testing Notes

Record your observations:
- **WebSocket Connection**: ____________
- **AI Audio Quality**: ____________
- **Recording Works**: ____________
- **Transcription Accuracy**: ____________
- **Interview Flow**: ____________
- **Any Errors**: ____________

---

**Ready to test!** Navigate to http://localhost:3000 and follow the steps above. ğŸš€
